# 并行计算

本文档由[deepseek](https://chat.deepseek.com/)友情支持。

[toc]

## MPI

这儿是一个学习链接https://hpc-tutorials.llnl.gov/mpi/



### 第一个mpi程序hello-world：

~~~c
#include <mpi.h>
#include <stdio.h>

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);  // 初始化 MPI
	//MPI_Init(NULL,NULL);
    
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);  // 获取当前进程的秩
    MPI_Comm_size(MPI_COMM_WORLD, &size);  // 获取进程总数

	//your code here
	
    printf("Hello from process %d of %d\n", rank, size);
    
    //end of code

    MPI_Finalize();  // 终止 MPI
    return 0;
}
~~~



### 一些关键概念：

| 概念                      | 说明                                                    |
| :------------------------ | :------------------------------------------------------ |
| **进程 (Process)**        | 每个 MPI 程序由多个独立进程组成，每个进程有独立内存。   |
| **通信器 (Communicator)** | 进程组的通信域（默认 `MPI_COMM_WORLD` 包含所有进程）。  |
| **秩 (Rank)**             | 进程在通信器中的唯一 ID（从 0 开始）。                  |
| **点对点通信**            | `MPI_Send()` 发送消息，`MPI_Recv()` 接收消息。          |
| **集体通信**              | `MPI_Bcast()` 广播、`MPI_Reduce()` 全局计算（如求和）。 |

### 主要函数介绍：

#### MPI_Send()和MPI_Recv():

~~~
// 发送数据
MPI_Send(
    void* data,          // 发送缓冲区
    int count,           // 数据类型发送的元素数量（非字节数！与 msg_type 共同决定总字节大小）
    MPI_Datatype type,   // 数据类型（如 MPI_INT）
    int dest_rank,       // 目标进程的秩
    int tag,             // 消息标签（用于区分用于区分同一进程发送的不同类型消息）,也	就是说send方和recv方的tag必须相同。这是你为他们约定好的一个接头暗号。
  
    MPI_Comm comm        // 通讯子，定义参与通信的进程组，常用 MPI_COMM_WORLD）
);

// 接收数据
MPI_Recv(
    void* data,          // 接收缓冲区
    int count,			 // 数据数量，注意是多少个数据(数据类型)。
    MPI_Datatype type,
    int source_rank,     // 发送进程的秩
    int tag,
    MPI_Comm comm,
    MPI_Status* status   // 接收状态（可忽略为 MPI_STATUS_IGNORE）
);
集体通信
~~~

实例：

~~~c
#include <mpi.h>
#include <stdio.h>

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);
    
    int rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);

    if (rank == 0) {
        // 发送数据：数组 [5, 6, 7, 8]
        int data[4] = {5, 6, 7, 8};
        MPI_Send(
            data,           // 缓冲区指针
            4,              // 发送4个元素
            MPI_INT,        // 数据类型为整型
            1,              // 目标进程 rank=1
            0,              // 消息标签=0
            MPI_COMM_WORLD  // 使用全局通信子
        );
        printf("Process 0 sent data.\n");
    } else if (rank == 1) {
        // 接收数据
        int received[4];
        MPI_Recv(
            received, 
            4, 
            MPI_INT, 
            0,              // 来源进程 rank=0
            0,              // 匹配标签=0
            MPI_COMM_WORLD, 
            MPI_STATUS_IGNORE
        );
        printf("Process 1 received: %d, %d, %d, %d\n", 
               received[0], received[1], received[2], received[3]);
    }

    MPI_Finalize();
    return 0;
}
~~~



#### MPI_Reduce():

~~~
int MPI_Reduce(
    const void*  sendbuf,     // 输入数据缓冲区（每个进程的本地数据）
    void*        recvbuf,     // 输出数据缓冲区（仅根进程有效）
    int          count,       // 数据元素个数
    MPI_Datatype datatype,    // 数据类型（如 MPI_INT）
    MPI_Op       op,          // 规约操作（如 MPI_SUM）
    int          root,        // 根进程的 rank（结果接收者）
    MPI_Comm     comm         // 通信子
);

~~~

 **参数详解**

| 参数       | 作用                                                         | 注意事项                                            |
| :--------- | :----------------------------------------------------------- | :-------------------------------------------------- |
| `sendbuf`  | 指向各进程本地数据的指针（所有进程必须提供有效数据）         | 数据在发送前应完成本地计算                          |
| `recvbuf`  | 仅根进程需分配内存，存储规约结果；非根进程可设为 `NULL`      | 非根进程的 `recvbuf` 不会被访问                     |
| `count`    | 每个进程参与规约的数据元素数量（所有进程的 `count` 必须一致） | 例如：若每个进程发送一个整数，`count=1`             |
| `datatype` | 数据类型的 MPI 标识符（所有进程必须一致）                    | 支持 `MPI_INT`, `MPI_DOUBLE`, `MPI_FLOAT` 等        |
| `op`       | 规约操作符（所有进程必须一致）                               | 支持 `MPI_SUM`, `MPI_MAX`, `MPI_MIN`, `MPI_PROD` 等 |
| `root`     | 指定接收结果的进程 rank（范围：0 ≤ root < 进程总数）         | 所有进程必须指定相同的 `root`                       |
| `comm`     | 通信子（定义参与操作的进程组）                               | 常用 `MPI_COMM_WORLD`                               |

 **支持的规约操作（MPI_Op）**

| 操作符       | 功能                 | 适用数据类型     |
| :----------- | :------------------- | :--------------- |
| `MPI_SUM`    | 求和                 | 整数、浮点数     |
| `MPI_MAX`    | 取最大值             | 整数、浮点数     |
| `MPI_MIN`    | 取最小值             | 整数、浮点数     |
| `MPI_PROD`   | 求乘积               | 整数、浮点数     |
| `MPI_LAND`   | 逻辑与 (Logical AND) | 整数（非零为真） |
| `MPI_BAND`   | 按位与 (Bitwise AND) | 整数、字节       |
| `MPI_LOR`    | 逻辑或 (Logical OR)  | 整数             |
| `MPI_MAXLOC` | 最大值及其位置       | 需自定义结构体   |
| `MPI_MINLOC` | 最小值及其位置       | 需自定义结构体   |

实例：

~~~c
#include <mpi.h>
#include <stdio.h>

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);
    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    int local_value = rank + 1;  // 每个进程的本地数据（如 1, 2, 3, 4）
    int global_sum;

    // 所有进程调用 MPI_Reduce，但只有根进程的 recvbuf 有效
    MPI_Reduce(
        &local_value,   // sendbuf（每个进程的数据）
        &global_sum,    // recvbuf（仅根进程需要）
        1,              // count（每个进程发送1个元素）
        MPI_INT,        // datatype
        MPI_SUM,        // op
        0,              // root（结果发送到 rank=0）
        MPI_COMM_WORLD
    );

    // 只有根进程输出结果
    if (rank == 0) {
        printf("Global sum = %d\n", global_sum);  // 4进程时输出 1+2+3+4=10
    }

    MPI_Finalize();
    return 0;
}

~~~



#### MPI_Bcast():

MPI_Bcast（Broadcast）是 MPI 中用于**广播数据**的集体通信函数，允许一个进程（称为 **根进程**）将数据发送给同一通信器内的所有其他进程。以下是各参数的详细说明及使用示例：

```
int MPI_Bcast(
    void*         buffer,     // 数据缓冲区指针（输入/输出）
    int           count,      // 数据元素个数
    MPI_Datatype  datatype,   // 数据类型（如 MPI_INT）
    int           root,       // 根进程的 rank（广播源）
    MPI_Comm      comm        // 通信子
);
```

------

 **参数详解**:

| 参数       | 作用                                                         | 注意事项                                    |
| :--------- | :----------------------------------------------------------- | :------------------------------------------ |
| `buffer`   | 数据缓冲区指针： - **根进程**：发送数据的内存地址 - **其他进程**：接收数据的内存地址 | 所有进程的 `buffer` 必须预分配足够空间      |
| `count`    | 数据元素数量（根进程发送的元素数，其他进程接收的元素数）     | 所有进程的 `count` 必须一致                 |
| `datatype` | 数据类型的 MPI 标识符（所有进程必须一致）                    | 支持 `MPI_INT`, `MPI_DOUBLE`, `MPI_CHAR` 等 |
| `root`     | 根进程的 rank（范围：0 ≤ root < 进程总数）                   | 所有进程必须指定相同的 `root`               |
| `comm`     | 通信子（定义参与广播的进程组）                               | 常用 `MPI_COMM_WORLD`                       |

------

### **核心特性**

1. **集体操作**
   所有进程必须调用 `MPI_Bcast`，包括根进程。如果某个进程未调用，程序将死锁。
2. **数据一致性**
   - **根进程**：`buffer` 包含待发送的数据，调用后数据保持不变。
   - **其他进程**：`buffer` 在调用后会被覆盖为根进程的数据。
3. **同步性**
   函数返回时，所有进程的 `buffer` 已包含根进程的数据（阻塞操作）。

实例：

~~~c
#include<stdio.h>
#include<mpi.h>

int main(int argc, char **argv)
{
	int myid, numprocs;
	int source = 0;
	int array[5]={1,2,3,4,5};
	int i;
	
	MPI_Init(&argc, &argv);
	
	MPI_Comm_rank(MPI_COMM_WORLD, &myid);
	MPI_Comm_size(MPI_COMM_WORLD, &numprocs);
    
    if(myid == source) {
        for(i = 1; i <= 5; i++)
            array[i] = i;
    }
    
    //your code here
    MPI_Bcast(array, 5, MPI_INT, source, MPI_COMM_WORLD);
    //end of your code
    
    if(myid != source) {
    	printf("In process %d, ", myid);
        for(i = 0; i < 5; i++)
            printf("arr[%d]=%d\t", i, array[i]);
        printf("\n");
	}

	MPI_Finalize();
	return 0;
}
~~~

#### MPI_Gather():

MPI_Gather 是 MPI 中用于**数据收集**的集体通信函数，允许根进程（Root Process）从所有进程（包括自身）收集数据块，并按进程 rank 顺序拼接成连续数组。以下是对各参数的详细说明及使用示例：

```
int MPI_Gather(
    const void* sendbuf,    // 发送缓冲区指针（每个进程的数据源）
    int sendcount,          // 每个进程发送的元素个数
    MPI_Datatype sendtype,  // 发送数据类型
    void* recvbuf,          // 接收缓冲区指针（仅根进程有效）
    int recvcount,          // 根进程从每个进程接收的元素个数
    MPI_Datatype recvtype,  // 接收数据类型（通常与 sendtype 相同）
    int root,               // 根进程的 rank
    MPI_Comm comm           // 通信子
);
```

------

 **参数详解**

| 参数        | 作用                                                         | 规则与示例                                                   |
| :---------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| `sendbuf`   | 各进程待发送数据的起始地址（非根进程必须有效）               | 非根进程需确保 `sendbuf` 包含 `sendcount` 个元素             |
| `sendcount` | **每个进程**发送的元素个数（所有进程的 `sendcount` 必须相同） | 示例：若每个进程发送 3 个 `int`，则 `sendcount=3`            |
| `sendtype`  | 发送数据的 MPI 数据类型（如 `MPI_INT`）                      | 所有进程的 `sendtype` 必须一致                               |
| `recvbuf`   | 根进程的接收缓冲区（需预分配足够空间，非根进程可设为 `NULL`） | 缓冲区大小 = `recvcount * comm_size`（如 4 进程 × 3 元素 = 12 元素） |
| `recvcount` | 根进程**从每个进程**接收的元素个数（必须等于 `sendcount`）   | 若使用 `MPI_Gatherv` 可接收不同数量的数据                    |
| `recvtype`  | 接收数据的 MPI 数据类型（通常与 `sendtype` 相同）            | 若不同，需满足类型兼容（如 `MPI_INT` 与 `MPI_LONG` 可能不兼容） |
| `root`      | 根进程的 rank（所有进程必须指定相同值）                      | 范围：`0 ≤ root < MPI_Comm_size(comm)`                       |
| `comm`      | 通信子（定义参与操作的进程组）                               | 常用 `MPI_COMM_WORLD`                                        |

------

 **核心行为**

1. **数据收集逻辑**
   - 根进程的 `recvbuf` 按进程 rank 顺序存储数据。
   - 例如：进程 0 的数据存放在 `recvbuf[0..sendcount-1]`，进程 1 的数据在 `recvbuf[sendcount..2*sendcount-1]`，以此类推。
2. **集体操作**
   所有进程必须调用 `MPI_Gather`，包括根进程。若某个进程未调用，程序将死锁。
3. **同步性**
   函数返回时，根进程的 `recvbuf` 已包含所有进程的数据（阻塞操作）。


**实例**：

~~~c
#include<stdio.h>
#include<mpi.h>

int main(int argc, char **argv)
{
	int myid, numprocs;
	int dest = 0;
	int array[5]={1,2,3,4,5};
	int *rbuf; 
	int i,j;

	MPI_Init(&argc, &argv);
	
	MPI_Comm_rank(MPI_COMM_WORLD, &myid);
	MPI_Comm_size(MPI_COMM_WORLD, &numprocs);
    
    if(myid == dest) {
    	rbuf=(int *)malloc(numprocs*5*sizeof(int));
	}

	//your code here
	MPI_Gather(array, 5, MPI_INT, rbuf, 5, MPI_INT, dest, MPI_COMM_WORLD);
	//end of your code
	
	if(myid == dest) {
		for(i=dest+1;i<numprocs;i++) {
			printf("Now is process %d's data: ", i);
			for(j=0;j<5;j++) {
				printf("array[%d]=%d\t", j, rbuf[i*5+j]);
			}
			printf("\n");
		}
	}
	
	MPI_Finalize();
	return 0;
} 
~~~



## OpenMP



## Pthread

